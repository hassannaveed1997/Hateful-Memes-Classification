{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb617da2",
   "metadata": {
    "id": "bb617da2"
   },
   "source": [
    "# RoBERTa Text Classifier (PyTorch)\n",
    "Source: https://pytorch.org/text/stable/tutorials/sst2_classification_non_distributed.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "LZGu3nQ5L-Ws",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22814,
     "status": "ok",
     "timestamp": 1651005306011,
     "user": {
      "displayName": "Dan Tylutki",
      "userId": "06618031331683857202"
     },
     "user_tz": -120
    },
    "id": "LZGu3nQ5L-Ws",
    "outputId": "09a4b572-8801-4c6f-a2cc-38d243c60716"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext in /opt/conda/lib/python3.7/site-packages (0.12.0)\n",
      "Requirement already satisfied: torch==1.11.0 in /opt/conda/lib/python3.7/site-packages (from torchtext) (1.11.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchtext) (1.19.5)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchtext) (2.27.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from torchtext) (4.63.0)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.11.0->torchtext) (4.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext) (1.26.8)\n"
     ]
    }
   ],
   "source": [
    "ENVIRONMENT = 'gcp'  # gcp, colab, or local\n",
    "if ENVIRONMENT == 'colab':\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    %cd '/content/drive/MyDrive/deep-learning-project/roberta_text_classifier'\n",
    "    data_path = '../data'\n",
    "elif ENVIRONMENT == 'gcp':\n",
    "    !pip install torchtext\n",
    "    data_path = 'gs://hateful_memes/hateful_memes'\n",
    "else:\n",
    "    data_path = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e54ea4bb",
   "metadata": {
    "executionInfo": {
     "elapsed": 3588,
     "status": "ok",
     "timestamp": 1651005309593,
     "user": {
      "displayName": "Dan Tylutki",
      "userId": "06618031331683857202"
     },
     "user_tz": -120
    },
    "id": "e54ea4bb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1ac157",
   "metadata": {
    "id": "4e1ac157"
   },
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f0d95a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "5de1099d18e749d884854a25f61477a4",
      "79c68a24d950424d83426210f87fd105",
      "9b7c72bdfe5e4ea5bc6218bdbc04415a",
      "6207b8c553e84955bfa17bbfe2f0407b",
      "3fc695c63e38441ba08427ed1c8c9942",
      "fa6f8ee45ef14aa38f897feefd7e0df8",
      "d8cacc2add4c4d608dec92e4662a7a0b",
      "93450a581c7e4adea684712be861e072",
      "67e61b4535204e12b0adf35dc6b5857f",
      "57fa367de05f4cb0a22c0909a1a7fc81",
      "30413fff2570489dbf5d21077c059c30"
     ]
    },
    "executionInfo": {
     "elapsed": 1441,
     "status": "ok",
     "timestamp": 1651005311026,
     "user": {
      "displayName": "Dan Tylutki",
      "userId": "06618031331683857202"
     },
     "user_tz": -120
    },
    "id": "1f0d95a0",
    "outputId": "a51b3182-da7d-45dc-df3c-d980fdd56c9c"
   },
   "outputs": [],
   "source": [
    "import torchtext.transforms as T\n",
    "from torch.hub import load_state_dict_from_url\n",
    "\n",
    "class PadTransform(nn.Module):\n",
    "  \"\"\"Pad tensor to fixed length\"\"\"\n",
    "  def __init__(self, max_length: int, pad_value: int):\n",
    "    super().__init__()\n",
    "    self.max_length = max_length\n",
    "    self.pad_value = pad_value\n",
    "\n",
    "  def forward(self, x):\n",
    "    \"\"\"\n",
    "    :param x: The tensor to pad\n",
    "    :type x: Tensor\n",
    "    :return: Tensor padded up to max_length with pad value\n",
    "    :rtype: Tensor\n",
    "    \"\"\"\n",
    "    if type(x) == list:\n",
    "      while len(x) < self.max_length:\n",
    "        x.append(self.pad_value)\n",
    "    else:\n",
    "      max_encoded_length = x.size(-1)\n",
    "      if max_encoded_length < self.max_length:\n",
    "        pad_amount = self.max_length - max_encoded_length\n",
    "        x = torch.nn.functional.pad(x, (0, pad_amount), value=self.pad_value)\n",
    "    return x\n",
    "\n",
    "padding_idx = 1\n",
    "bos_idx = 0\n",
    "eos_idx = 2\n",
    "max_seq_len = 50  # 256\n",
    "xlmr_vocab_path = r\"https://download.pytorch.org/models/text/xlmr.vocab.pt\"\n",
    "xlmr_spm_model_path = r\"https://download.pytorch.org/models/text/xlmr.sentencepiece.bpe.model\"\n",
    "\n",
    "text_transform = T.Sequential(\n",
    "    T.SentencePieceTokenizer(xlmr_spm_model_path),\n",
    "    T.VocabTransform(load_state_dict_from_url(xlmr_vocab_path)),\n",
    "    T.Truncate(max_seq_len - 2),\n",
    "    T.AddToken(token=bos_idx, begin=True),\n",
    "    T.AddToken(token=eos_idx, begin=False),\n",
    "    PadTransform(max_length=max_seq_len, pad_value=padding_idx)\n",
    ")\n",
    "\n",
    "# Alternative method\n",
    "#from torchtext.models import XLMR_BASE_ENCODER\n",
    "#text_transform = XLMR_BASE_ENCODER.transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e2ac2a",
   "metadata": {
    "id": "10e2ac2a"
   },
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "160fff59",
   "metadata": {
    "executionInfo": {
     "elapsed": 1767,
     "status": "ok",
     "timestamp": 1651005312787,
     "user": {
      "displayName": "Dan Tylutki",
      "userId": "06618031331683857202"
     },
     "user_tz": -120
    },
    "id": "160fff59"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Train Data\n",
    "train = pd.read_csv(f'{data_path}/train_captioned.csv')\n",
    "train['context'] = train['text'] + '. ' + train['caption']\n",
    "train.drop(columns=['Unnamed: 0', 'text', 'caption'], inplace=True)\n",
    "\n",
    "train = train[['context', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7a6a225",
   "metadata": {
    "executionInfo": {
     "elapsed": 921,
     "status": "ok",
     "timestamp": 1651005313701,
     "user": {
      "displayName": "Dan Tylutki",
      "userId": "06618031331683857202"
     },
     "user_tz": -120
    },
    "id": "c7a6a225"
   },
   "outputs": [],
   "source": [
    "# Validation Data\n",
    "valid = pd.read_csv(f'{data_path}/dev_unseen_captioned.csv')\n",
    "#valid = pd.read_csv('../data/dev_seen_captioned.csv')\n",
    "#valid = pd.read_csv('../data/test_unseen_captioned.csv')\n",
    "#valid = pd.read_csv('../data/test_seen_captioned.csv')\n",
    "valid['context'] = valid['text'] + '. ' + valid['caption']\n",
    "valid.drop(columns=['Unnamed: 0', 'text', 'caption'], inplace=True)\n",
    "\n",
    "dev = valid[['context', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ce63373",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1651005313702,
     "user": {
      "displayName": "Dan Tylutki",
      "userId": "06618031331683857202"
     },
     "user_tz": -120
    },
    "id": "2ce63373"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "  def __init__(self, text, labels):\n",
    "    self.label = labels\n",
    "    self.text = text\n",
    "    self.token_ids = text.apply(lambda x: text_transform(x))\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.label)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    label = self.label[idx]\n",
    "    text = self.text[idx]\n",
    "    token_ids = self.token_ids[idx]\n",
    "    sample = {\"text\": text, \"token_ids\": token_ids, \"label\": label}\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "If9PZgOFQD1z",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1651005313703,
     "user": {
      "displayName": "Dan Tylutki",
      "userId": "06618031331683857202"
     },
     "user_tz": -120
    },
    "id": "If9PZgOFQD1z"
   },
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(text=train['context'], labels=train['label'])\n",
    "dev_dataset = TextDataset(text=dev['context'], labels=dev['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "I1FhuZUbfQlf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1651005313704,
     "user": {
      "displayName": "Dan Tylutki",
      "userId": "06618031331683857202"
     },
     "user_tz": -120
    },
    "id": "I1FhuZUbfQlf",
    "outputId": "3626b64c-2d1b-402b-8aca-2614dd10ffdb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'no one: steven hawking:. a black and white photo of a computer keyboard and mouse.',\n",
       " 'token_ids': [0,\n",
       "  110,\n",
       "  1632,\n",
       "  12,\n",
       "  2288,\n",
       "  1353,\n",
       "  6,\n",
       "  187404,\n",
       "  214,\n",
       "  12,\n",
       "  5,\n",
       "  10,\n",
       "  22556,\n",
       "  136,\n",
       "  35011,\n",
       "  16186,\n",
       "  111,\n",
       "  10,\n",
       "  13909,\n",
       "  149186,\n",
       "  136,\n",
       "  114669,\n",
       "  5,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[7001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0d28ec3",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1651005313705,
     "user": {
      "displayName": "Dan Tylutki",
      "userId": "06618031331683857202"
     },
     "user_tz": -120
    },
    "id": "c0d28ec3"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16  # original: 16,  if None: batch size appears to be 1\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dev_dataloader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f6e429",
   "metadata": {
    "id": "55f6e429"
   },
   "source": [
    "## Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f4bec01",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "9b4c914389e5411db0bd3c9a91c4d8ef",
      "e42cb3c778144cbaa559696db8ba6e4f",
      "54263fe9a57e41a4bce7016e98be782c",
      "ca165ea427f64e74973327cd3e19402b",
      "0c26b13070a44361b7d71d8c10b0b03d",
      "4b1f49bd523b41bd9b30bf741dd4e956",
      "2fcca3a1bf2e49a3bda012c58d404a5f",
      "8c3b323e61c34410aa120240581d8f16",
      "e82d2819e33443d29d876e48dd313317",
      "19a254dc214c4062a32a733e32c9f03f",
      "92a4415959f0471c8ce29ee68dc952ba"
     ]
    },
    "executionInfo": {
     "elapsed": 18808,
     "status": "ok",
     "timestamp": 1651005332504,
     "user": {
      "displayName": "Dan Tylutki",
      "userId": "06618031331683857202"
     },
     "user_tz": -120
    },
    "id": "6f4bec01",
    "outputId": "a058f5b9-d05b-4a60-94b8-d4642582b499"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (encoder): RobertaEncoder(\n",
       "    (transformer): TransformerEncoder(\n",
       "      (token_embedding): Embedding(250002, 768, padding_idx=1)\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (attention): MultiheadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (input_projection): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (residual_mlp): ResidualMLP(\n",
       "            (mlp): Sequential(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU()\n",
       "              (2): Dropout(p=0.1, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (4): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (attention_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (attention): MultiheadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (input_projection): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (residual_mlp): ResidualMLP(\n",
       "            (mlp): Sequential(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU()\n",
       "              (2): Dropout(p=0.1, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (4): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (attention_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (attention): MultiheadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (input_projection): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (residual_mlp): ResidualMLP(\n",
       "            (mlp): Sequential(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU()\n",
       "              (2): Dropout(p=0.1, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (4): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (attention_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (attention): MultiheadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (input_projection): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (residual_mlp): ResidualMLP(\n",
       "            (mlp): Sequential(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU()\n",
       "              (2): Dropout(p=0.1, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (4): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (attention_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerEncoderLayer(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (attention): MultiheadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (input_projection): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (residual_mlp): ResidualMLP(\n",
       "            (mlp): Sequential(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU()\n",
       "              (2): Dropout(p=0.1, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (4): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (attention_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerEncoderLayer(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (attention): MultiheadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (input_projection): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (residual_mlp): ResidualMLP(\n",
       "            (mlp): Sequential(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU()\n",
       "              (2): Dropout(p=0.1, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (4): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (attention_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): TransformerEncoderLayer(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (attention): MultiheadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (input_projection): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (residual_mlp): ResidualMLP(\n",
       "            (mlp): Sequential(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU()\n",
       "              (2): Dropout(p=0.1, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (4): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (attention_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): TransformerEncoderLayer(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (attention): MultiheadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (input_projection): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (residual_mlp): ResidualMLP(\n",
       "            (mlp): Sequential(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU()\n",
       "              (2): Dropout(p=0.1, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (4): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (attention_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): TransformerEncoderLayer(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (attention): MultiheadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (input_projection): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (residual_mlp): ResidualMLP(\n",
       "            (mlp): Sequential(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU()\n",
       "              (2): Dropout(p=0.1, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (4): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (attention_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): TransformerEncoderLayer(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (attention): MultiheadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (input_projection): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (residual_mlp): ResidualMLP(\n",
       "            (mlp): Sequential(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU()\n",
       "              (2): Dropout(p=0.1, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (4): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (attention_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): TransformerEncoderLayer(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (attention): MultiheadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (input_projection): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (residual_mlp): ResidualMLP(\n",
       "            (mlp): Sequential(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU()\n",
       "              (2): Dropout(p=0.1, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (4): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (attention_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): TransformerEncoderLayer(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (attention): MultiheadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (input_projection): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (residual_mlp): ResidualMLP(\n",
       "            (mlp): Sequential(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU()\n",
       "              (2): Dropout(p=0.1, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (4): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (attention_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (positional_embedding): PositionalEmbedding(\n",
       "        (embedding): Embedding(514, 768, padding_idx=1)\n",
       "      )\n",
       "      (embedding_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (head): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "    (activation_fn): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 2\n",
    "input_dim = 768  # 768\n",
    "\n",
    "from torchtext.models import RobertaClassificationHead, XLMR_BASE_ENCODER\n",
    "classifier_head = RobertaClassificationHead(num_classes=num_classes, input_dim=input_dim)\n",
    "model = XLMR_BASE_ENCODER.get_model(head=classifier_head)\n",
    "#model = ROBERTA_BASE_ENCODER.get_model(head=classifier_head)\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb43a521",
   "metadata": {
    "id": "cb43a521"
   },
   "source": [
    "## Training Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6eb129f9",
   "metadata": {
    "executionInfo": {
     "elapsed": 401,
     "status": "ok",
     "timestamp": 1651005939142,
     "user": {
      "displayName": "Dan Tylutki",
      "userId": "06618031331683857202"
     },
     "user_tz": -120
    },
    "id": "6eb129f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model checkpoint could not be loaded: [Errno 2] No such file or directory: 'model.pt'\n"
     ]
    }
   ],
   "source": [
    "import torchtext.functional as F\n",
    "from torch.optim import AdamW\n",
    "\n",
    "learning_rate = 1e-3  # 1e-5\n",
    "\n",
    "optim = AdamW(model.parameters(), lr=learning_rate)\n",
    "#criteria = nn.CrossEntropyLoss()\n",
    "criteria = nn.BCEWithLogitsLoss()\n",
    "#sigmoid = nn.Sigmoid()\n",
    "#criteria = nn.BCELoss()\n",
    "\n",
    "\n",
    "# Load model checkpoint if one exists\n",
    "LOAD_MODEL = True\n",
    "if LOAD_MODEL:\n",
    "  from os import listdir\n",
    "  try:\n",
    "    checkpoint = torch.load('model.pt')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optim.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    accuracy = checkpoint['accuracy']\n",
    "  except Exception as e:\n",
    "    print(\"Model checkpoint could not be loaded:\", e)\n",
    "\n",
    "\n",
    "def train_step(input, target):\n",
    "    output = model(input)  # original\n",
    "    #output = torch.argmax(model(input), dim=1).type(torch.float)  # use with BCELoss\n",
    "    #output = model(input).requires_grad_(True)\n",
    "    #preds = torch.argmax(output, dim=1).type(torch.float)#.requires_grad_(True)\n",
    "    #loss = torch.sum(torch.abs(torch.sub(preds, target))).requires_grad_(True)\n",
    "    #loss = criteria(preds, target).requires_grad_(True)\n",
    "    loss = criteria(output, target)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "\n",
    "def eval_step(input, target):\n",
    "    output = model(input)  # original\n",
    "    #output = torch.argmax(model(input), dim=1)\n",
    "    #target = target.squeeze(1)\n",
    "    #loss = torch.sum(torch.abs(torch.sub(preds, target)))\n",
    "    loss = criteria(output, target).item()\n",
    "    #return float(loss), (output.argmax(1) == target).type(torch.float).sum().item()\n",
    "    return float(loss), (output.argmax(1) == target.argmax(1)).type(torch.float).sum().item()\n",
    "\n",
    "\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    counter = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dev_dataloader:\n",
    "            \n",
    "            batch_token_ids = []\n",
    "            for b in range(BATCH_SIZE):\n",
    "                try:\n",
    "                    token_ids_b = []\n",
    "                    for i in range(max_seq_len):\n",
    "                        token_ids_b.append(batch['token_ids'][i][b].item())\n",
    "                    batch_token_ids.append(token_ids_b)\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            input = F.to_tensor(batch_token_ids, padding_value=padding_idx).to(DEVICE)\n",
    "            #input = F.to_tensor(batch['token_ids'], padding_value=padding_idx).view(1,-1).to(DEVICE)\n",
    "            target = torch.tensor(batch['label']).to(DEVICE)\n",
    "            target = torch.nn.functional.one_hot(\n",
    "                target.clone().detach(), \n",
    "                num_classes=num_classes\n",
    "            ).type(torch.float).to(DEVICE)\n",
    "            loss, predictions = eval_step(input, target)\n",
    "            total_loss += loss\n",
    "            correct_predictions += predictions\n",
    "            total_predictions += len(target)\n",
    "            counter += 1\n",
    "\n",
    "    return total_loss / counter, correct_predictions / total_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a63053",
   "metadata": {
    "id": "84a63053"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "57f25192",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57f25192",
    "outputId": "cb87c127-7c35-4e5f-d639-690421eb6d6e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:72: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = [0], loss = [0.6635420269825879], accuracy = [0.6296296296296297]\n",
      "Epoch = [1], loss = [0.6626101241392248], accuracy = [0.6296296296296297]\n",
      "Epoch = [2], loss = [0.6593696369844324], accuracy = [0.6296296296296297]\n",
      "Epoch = [3], loss = [0.6587388760903302], accuracy = [0.6296296296296297]\n",
      "Epoch = [4], loss = [0.6629548923057669], accuracy = [0.6296296296296297]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for e in range(num_epochs):\n",
    "  for batch in train_dataloader:\n",
    "    \n",
    "    # convert batch['token_ids'] into list of lists where each sub-list contains the tokens for sequence. \n",
    "    # This is done because tokens are coming in as list of tensors where tensor i has ith token for all sequences...\n",
    "    batch_token_ids = []\n",
    "    for b in range(BATCH_SIZE):\n",
    "        try:\n",
    "            token_ids_b = []\n",
    "            for i in range(max_seq_len):\n",
    "                token_ids_b.append(batch['token_ids'][i][b].item())\n",
    "            batch_token_ids.append(token_ids_b)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    input = F.to_tensor(batch_token_ids, padding_value=padding_idx).to(DEVICE)\n",
    "    #input = F.to_tensor(batch['token_ids'], padding_value=padding_idx).view(1,-1).to(DEVICE)\n",
    "    target = torch.tensor(batch['label']).to(DEVICE)\n",
    "    target = torch.nn.functional.one_hot(\n",
    "        target.clone().detach(), \n",
    "        num_classes=num_classes\n",
    "    #).view(-1, num_classes).type(torch.float).requires_grad_(True).to(DEVICE)\n",
    "    ).type(torch.float).requires_grad_(True).to(DEVICE)\n",
    "    train_step(input, target)\n",
    "\n",
    "  loss, accuracy = evaluate()\n",
    "  print(\"Epoch = [{}], loss = [{}], accuracy = [{}]\".format(e, loss, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jfK3Ju3l02l4",
   "metadata": {
    "id": "jfK3Ju3l02l4"
   },
   "source": [
    "# Save Model Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "53f8cc89",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "aborted",
     "timestamp": 1651005773411,
     "user": {
      "displayName": "Dan Tylutki",
      "userId": "06618031331683857202"
     },
     "user_tz": -120
    },
    "id": "53f8cc89"
   },
   "outputs": [],
   "source": [
    "SAVE_MODEL = True\n",
    "\n",
    "if SAVE_MODEL:\n",
    "\n",
    "  PATH = 'model.pt'\n",
    "\n",
    "  try:\n",
    "    EPOCH = e\n",
    "  except:\n",
    "    EPOCH = num_epochs\n",
    "\n",
    "  torch.save(\n",
    "      {\n",
    "        'epoch': EPOCH,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optim.state_dict(),\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy\n",
    "      }, \n",
    "      PATH\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dXhoYXRJ7wiw",
   "metadata": {
    "id": "dXhoYXRJ7wiw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "roberta_pytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0c26b13070a44361b7d71d8c10b0b03d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "19a254dc214c4062a32a733e32c9f03f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2fcca3a1bf2e49a3bda012c58d404a5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "30413fff2570489dbf5d21077c059c30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3fc695c63e38441ba08427ed1c8c9942": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b1f49bd523b41bd9b30bf741dd4e956": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54263fe9a57e41a4bce7016e98be782c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c3b323e61c34410aa120240581d8f16",
      "max": 1109857305,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e82d2819e33443d29d876e48dd313317",
      "value": 1109857305
     }
    },
    "57fa367de05f4cb0a22c0909a1a7fc81": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5de1099d18e749d884854a25f61477a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_79c68a24d950424d83426210f87fd105",
       "IPY_MODEL_9b7c72bdfe5e4ea5bc6218bdbc04415a",
       "IPY_MODEL_6207b8c553e84955bfa17bbfe2f0407b"
      ],
      "layout": "IPY_MODEL_3fc695c63e38441ba08427ed1c8c9942"
     }
    },
    "6207b8c553e84955bfa17bbfe2f0407b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_57fa367de05f4cb0a22c0909a1a7fc81",
      "placeholder": "​",
      "style": "IPY_MODEL_30413fff2570489dbf5d21077c059c30",
      "value": " 4.85M/4.85M [00:00&lt;00:00, 7.86MB/s]"
     }
    },
    "67e61b4535204e12b0adf35dc6b5857f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "79c68a24d950424d83426210f87fd105": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa6f8ee45ef14aa38f897feefd7e0df8",
      "placeholder": "​",
      "style": "IPY_MODEL_d8cacc2add4c4d608dec92e4662a7a0b",
      "value": "100%"
     }
    },
    "8c3b323e61c34410aa120240581d8f16": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92a4415959f0471c8ce29ee68dc952ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "93450a581c7e4adea684712be861e072": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b4c914389e5411db0bd3c9a91c4d8ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e42cb3c778144cbaa559696db8ba6e4f",
       "IPY_MODEL_54263fe9a57e41a4bce7016e98be782c",
       "IPY_MODEL_ca165ea427f64e74973327cd3e19402b"
      ],
      "layout": "IPY_MODEL_0c26b13070a44361b7d71d8c10b0b03d"
     }
    },
    "9b7c72bdfe5e4ea5bc6218bdbc04415a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93450a581c7e4adea684712be861e072",
      "max": 5082095,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_67e61b4535204e12b0adf35dc6b5857f",
      "value": 5082095
     }
    },
    "ca165ea427f64e74973327cd3e19402b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_19a254dc214c4062a32a733e32c9f03f",
      "placeholder": "​",
      "style": "IPY_MODEL_92a4415959f0471c8ce29ee68dc952ba",
      "value": " 1.03G/1.03G [00:14&lt;00:00, 73.0MB/s]"
     }
    },
    "d8cacc2add4c4d608dec92e4662a7a0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e42cb3c778144cbaa559696db8ba6e4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b1f49bd523b41bd9b30bf741dd4e956",
      "placeholder": "​",
      "style": "IPY_MODEL_2fcca3a1bf2e49a3bda012c58d404a5f",
      "value": "100%"
     }
    },
    "e82d2819e33443d29d876e48dd313317": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fa6f8ee45ef14aa38f897feefd7e0df8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
